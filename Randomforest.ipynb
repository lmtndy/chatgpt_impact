{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjLsBzWowz7I"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBmx5s5ZxDyN"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "    # Đọc tệp Excel\n",
        "data = pd.read_excel('NCKH_dachuanhoa.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhg6Dguw2zMb"
      },
      "outputs": [],
      "source": [
        "# Get feature and target column\n",
        "y = data[\"Cau14'\"].copy()\n",
        "X = data[['Cau11','Cau12','Cau21','Cau22','Cau23','Cau24','Cau25','Cau26','Cau28','Cau29','Cau30', 'Cau31','Cau32','Cau33','Cau34']].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWgR4EPc3BKQ"
      },
      "outputs": [],
      "source": [
        "    # Sử dụng hàm train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKMDVvL4DB69",
        "outputId": "43d73422-19d9-42d7-e698-76be09cbcbf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6395348837209303\n"
          ]
        }
      ],
      "source": [
        "def Kfold(X, y ,k = 5):\n",
        "  acc = []\n",
        "  rf_model = []\n",
        "  for k in range(k):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7, shuffle = True)\n",
        "    clf = RandomForestClassifier(n_estimators = 150, min_samples_leaf=4,\n",
        "                             max_features = 3, min_samples_split= 3)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # Tính độ chính xác\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    acc.append(accuracy)\n",
        "    rf_model.append(clf)\n",
        "  return rf_model, acc\n",
        "\n",
        "rf_model, acc  = Kfold(X, y, k= 100)\n",
        "print(max(acc))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQw_4_oAnOrt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Tạo hàm Kfold với thêm Grid Search\n",
        "def KfoldWithGridSearch(X, y, k=5):\n",
        "    acc = []\n",
        "    rf_models = []\n",
        "\n",
        "    for _ in range(k):\n",
        "        # Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7, shuffle=True)\n",
        "\n",
        "        # Định nghĩa mô hình RandomForest\n",
        "        clf = RandomForestClassifier(random_state=7, bootstrap=True)\n",
        "\n",
        "        # Thiết lập các giá trị thử nghiệm cho Grid Search\n",
        "        grid_space = {\n",
        "            'n_estimators': [100, 150, 200, 250, 300],\n",
        "            'max_features': [3, 5, 7, 9, 10, 12],\n",
        "            'min_samples_leaf': [4, 5, 6, 7, 8],\n",
        "            'min_samples_split': [3, 4, 5, 6, 7, 8]\n",
        "        }\n",
        "\n",
        "        # Sử dụng GridSearchCV để tìm kiếm siêu tham số tốt nhất\n",
        "        grid_search = GridSearchCV(estimator=clf, param_grid=grid_space, cv=3, scoring='accuracy')\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "        # Lấy mô hình tốt nhất từ Grid Search\n",
        "        best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "        # Dự đoán trên tập kiểm tra\n",
        "        y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "        # Tính độ chính xác\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        acc.append(accuracy)\n",
        "        rf_models.append(best_rf_model)\n",
        "\n",
        "    return rf_models, acc\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZQEh8ufoZaN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Gọi hàm KfoldWithGridSearch\n",
        "rf_models, acc = KfoldWithGridSearch(X, y, k=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRkTZYKVoZ-m"
      },
      "outputs": [],
      "source": [
        "# In ra độ chính xác cao nhất\n",
        "print(\"Max Accuracy:\", max(acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvnK5M0gC7jA"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier from scikit-learn\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Tạo mô hình phân loại\n",
        "grid_space={'n_estimators':[100,150, 200,250, 300],\n",
        "\n",
        "              'max_features':[3,5,7,9, 10, 12],\n",
        "              'min_samples_leaf':[4,5,6,7,8],\n",
        "              'min_samples_split':[3,4,5,6,7,8]\n",
        "           }\n",
        "clf = RandomForestClassifier(n_estimators = 150, min_samples_leaf=4,\n",
        "                             max_features = 3, min_samples_split= 3, random_state = 7,\n",
        "                             bootstrap=True)\n",
        "grid = GridSearchCV(clf,param_grid=grid_space,cv=3,scoring='accuracy')\n",
        "model_grid = grid.fit(X,y)\n",
        "\n",
        "# Fit mô hình với dữ liệu huấn luyện\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s4SKUMG7pzh"
      },
      "outputs": [],
      "source": [
        "print('Best hyperparameters are: '+str(model_grid.best_params_))\n",
        "print('Best score is: '+str(model_grid.best_score_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUOhcL1h74RK"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_YbmlrW75vc"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "importances = clf.feature_importances_\n",
        "feature_names = X.columns\n",
        "std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n",
        "forest_importances = pd.Series(importances, index=feature_names)\n",
        "\n",
        "# Sort feature importances in descending order\n",
        "forest_importances_sorted = forest_importances.sort_values(ascending=False)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "forest_importances_sorted.plot.bar(yerr=std, ax=ax)\n",
        "ax.set_title(\"Feature importances using MDI (Sorted)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9b7oT435CtS"
      },
      "source": [
        "Xây dựng model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgd9YWF21bul"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Xây dựng mô hình và thực hiện dự đoán trên dữ liệu kiểm tra\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Tính độ chính xác\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Tạo báo cáo phân loại\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Tính ma trận nhầm lẫn\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Hiển thị kết quả\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "print(\"Confusion Matrix:\\n\", matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu76dAzd8qGa"
      },
      "source": [
        "**Feature important**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gROdCLpL2ZpO"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Xây dựng mô hình\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Thực hiện dự đoán trên dữ liệu kiểm tra\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Tính ma trận nhầm lẫn\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Chuyển đổi ma trận nhầm lẫn thành tỷ lệ (chuẩn hóa)\n",
        "matrix_normalized = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Hiển thị ma trận nhầm lẫn dưới dạng heatmap (chuẩn hóa)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(matrix_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=clf.classes_, yticklabels=clf.classes_)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Normalized Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Xác định biến được dự đoán chính xác nhất\n",
        "correctly_predicted_variables = []\n",
        "for i in range(len(matrix)):\n",
        "    correctly_predicted_variables.append((X_test.columns[i], matrix[i, i]))\n",
        "\n",
        "# Sắp xếp theo số lần dự đoán đúng giảm dần\n",
        "correctly_predicted_variables.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# In ra biến được dự đoán chính xác nhất\n",
        "print(\"Top correctly predicted variables:\")\n",
        "for variable, count in correctly_predicted_variables:\n",
        "    print(f\"{variable}: {count} times correctly predicted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvINn2rGZrg2"
      },
      "outputs": [],
      "source": [
        "# Tính feature importance\n",
        "feature_importance = clf.feature_importances_\n",
        "\n",
        "# Tạo một DataFrame để hiển thị thông tin\n",
        "import pandas as pd\n",
        "feature_importance_df = pd.DataFrame({'Variable': X_train.columns, 'Importance': feature_importance})\n",
        "\n",
        "# Sắp xếp theo độ quan trọng giảm dần\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Hiển thị biểu đồ cột về độ quan trọng của các biến\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Variable', data=feature_importance_df, palette='viridis')\n",
        "\n",
        "# Thêm tiêu đề và định dạng\n",
        "plt.title('Feature Importance', fontsize=16)\n",
        "plt.xlabel('Importance', fontsize=14)\n",
        "plt.ylabel('Variable', fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "# Hiển thị giá trị của độ quan trọng trên từng cột\n",
        "for index, value in enumerate(feature_importance_df['Importance']):\n",
        "    plt.text(value, index, f'{value:.4f}', ha='left', va='center', fontsize=10, color='black')\n",
        "\n",
        "# Hiển thị lưới để dễ đọc\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "\n",
        "# Tăng khoảng cách giữa các cột để dễ nhìn\n",
        "plt.tight_layout()\n",
        "\n",
        "# Hiển thị biểu đồ\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5ZdOKfHA-IO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your data into the mc DataFrame\n",
        "mc = pd.read_excel('NCKH_dachuanhoa.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnoZY6P0Byc0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your data into the mc DataFrame\n",
        "mc = pd.read_excel('NCKH_dachuanhoa.xlsx')\n",
        "\n",
        "# Print the column names to identify the correct column\n",
        "print(mc.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scrmx3cxJDdf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load your data into the mc DataFrame\n",
        "mc = pd.read_excel('NCKH_dachuanhoa.xlsx')  # Replace 'your_data.xlsx' with your actual file path\n",
        "\n",
        "# Extract 'Cau12' and 'Cau14'' columns\n",
        "selected_data = mc[['Cau12', \"Cau14'\"]]\n",
        "\n",
        "# Map the values of 'Cau12' to the desired labels\n",
        "label_mapping = {\n",
        "    1: 'Rất ít',\n",
        "    2: 'Ít',\n",
        "    3: 'Trung bình',\n",
        "    4: 'Nhiều',\n",
        "    5: 'Rất nhiều'\n",
        "}\n",
        "\n",
        "selected_data['Cau12'] = selected_data['Cau12'].map(label_mapping)\n",
        "\n",
        "# Create a count plot using seaborn\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='Cau12', hue=\"Cau14'\", data=selected_data)\n",
        "plt.xlabel('Cau12')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Comparison of Cau12 and Cau14')\n",
        "plt.legend(title=\"Cau14'\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2fhZuLF9B2P"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e_Vs8Sf8nK5"
      },
      "source": [
        "Lưu FILE .pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OKKTNUx7zgR"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "filename = 'forest_model_GPT_new.pkl'\n",
        "\n",
        "# Mở tệp để ghi dữ liệu (chế độ 'wb' là ghi dưới dạng binary)\n",
        "with open(filename, 'wb') as file:\n",
        "    pickle.dump(data, file)\n",
        "\n",
        "# Đóng tệp\n",
        "# file.close()\n",
        "\n",
        "# Nạp dữ liệu từ tệp Pickle\n",
        "with open(filename, 'rb') as file:\n",
        "    loaded_data = pickle.load(file)\n",
        "\n",
        "# In ra dữ liệu đã được nạp từ tệp Pickle\n",
        "print(loaded_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HfIGuHtaToUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si9mOYsWMTNw"
      },
      "outputs": [],
      "source": [
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsVG0tvtmzyj"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "param = {'C': 0.5, 'degree': 3, 'gamma': 'scale', 'kernel': 'linear'}\n",
        "model =  svm.SVC( **param)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "# # Create a svm Classifier\n",
        "# for param in params:\n",
        "#     clf = svm.SVC(C=param[\"C\"], gamma=param[\"gamma\"], kernel=param[\"kernel\"], degree=param[\"degree\"])  # Linear Kernel\n",
        "\n",
        "#     # Train the model using the training sets\n",
        "#     clf.fit(X_train, y_train)\n",
        "\n",
        "#     # Predict the response for the test dataset\n",
        "#     y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"class 3\"],\n",
        "            yticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"class 3\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(f\"Confusion Matrix (C={param['C']}, gamma={param['gamma']}, kernel={param['kernel']}, degree={param['degree']})\")\n",
        "plt.show()\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "#     print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zQl2Ahzm5Li"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tạo model của bạn (ở đây là model của SVM)\n",
        "\n",
        "\n",
        "# Sử dụng RFE để đánh giá tầm quan trọng của các đặc trưng\n",
        "rfe = RFE(estimator=model)\n",
        "svm_rfe_model_fit = rfe.fit(X_train, y_train)\n",
        "\n",
        "# Lấy chỉ số của các đặc trưng được chọn\n",
        "selected_features = pd.Series(data=svm_rfe_model_fit.ranking_, index=X_train.columns)\n",
        "\n",
        "# Chọn chỉ các đặc trưng có rank bằng 1\n",
        "signi_feat_rfe = selected_features[selected_features == 1].index\n",
        "\n",
        "# Sắp xếp chỉ số của các đặc trưng được chọn theo rank\n",
        "sorted_features = selected_features.sort_values(ascending=False)\n",
        "\n",
        "# Vẽ biểu đồ tầm quan trọng của các đặc trưng sau khi sử dụng RFE (đã sắp xếp)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sorted_features.plot(kind='bar')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Ranking')\n",
        "plt.title('Feature Importance Ranking (RFE) - Sorted')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wvQY9tPa1xTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cho model có kernel là poly"
      ],
      "metadata": {
        "id": "WBHPzfKq1xYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "param = {'C': 1, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
        "model =  svm.SVC( **param)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "# # Create a svm Classifier\n",
        "# for param in params:\n",
        "#     clf = svm.SVC(C=param[\"C\"], gamma=param[\"gamma\"], kernel=param[\"kernel\"], degree=param[\"degree\"])  # Linear Kernel\n",
        "\n",
        "#     # Train the model using the training sets\n",
        "#     clf.fit(X_train, y_train)\n",
        "\n",
        "#     # Predict the response for the test dataset\n",
        "#     y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"class 3\"],\n",
        "            yticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"class 3\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(f\"Confusion Matrix (C={param['C']}, gamma={param['gamma']}, kernel={param['kernel']}, degree={param['degree']})\")\n",
        "plt.show()\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "#     print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "Y9rRBn6w19j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "perm_importance = permutation_importance(model, X_train, y_train)\n",
        "\n",
        "# Making the sum of feature importance being equal to 1.0,\n",
        "# so feature importance can be understood as percentage\n",
        "perm_importance_normalized = perm_importance.importances_mean/perm_importance.importances_mean.sum()\n",
        "\n",
        "# Feature's name (considering your X a DataFrame)\n",
        "feature_names = X.columns\n",
        "features = np.array(feature_names)\n",
        "\n",
        "# Sort to plot in order of importance\n",
        "sorted_idx = perm_importance_normalized.argsort()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(13,5))\n",
        "plt.title('Feature Importance',fontsize=20)\n",
        "plt.barh(features[sorted_idx], perm_importance_normalized[sorted_idx], color='b', align='center')\n",
        "plt.xlabel('Relative Importance', fontsize=15)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "for index, value in enumerate(perm_importance_normalized[sorted_idx]):\n",
        "    plt.text(value, index,\n",
        "             str(round(value,2)), fontsize=15)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bBwEkM0p11I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_column_charts(df, column_name):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "    # Biểu đồ tròn\n",
        "    df[column_name].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, ax=axes[0])\n",
        "    axes[0].set_title(f'Pie Chart for {column_name}')\n",
        "\n",
        "    # Biểu đồ cột\n",
        "    sns.countplot(x=column_name, data=df, palette='viridis', ax=axes[1])\n",
        "    axes[1].set_title(f'Column Chart for {column_name}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ví dụ sử dụng:\n",
        "# # Thay 'TenCot' bằng tên cột bạn muốn vẽ\n",
        "# plot_column_charts(df, 'TenCot')\n",
        "def view_data(df, name):\n",
        "  for i in range(1,5):\n",
        "    df_12 = df[df[\"Cau14'\"]==i]\n",
        "    plot_column_charts(df_12, name)\n"
      ],
      "metadata": {
        "id": "fveQ5pOgI01S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [ \"Cau19\", \"Cau24*\", 'Cau25' ,'Cau31']\n",
        "view_data(df, \"Cau19\")"
      ],
      "metadata": {
        "id": "FtghILOU-GAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "CcIQuVzJMdIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def delete_noise_threshold( df_name):\n",
        "  for column in df_name.columns:\n",
        "    if column != \"Cau14'\":\n",
        "      value_counts = df_name[column].value_counts(normalize=True)\n",
        "      # Xác định và loại bỏ giá trị nhiễu dựa trên phân phối xác suất của feature\n",
        "      threshold = 0.05\n",
        "      noise_values = value_counts[value_counts < threshold].index\n",
        "      df_name = df_name[~df_name[column].isin(noise_values)]\n",
        "  return df_name\n",
        "\n",
        "\n",
        "\n",
        "def delete_noise(df):\n",
        "  df_n = []\n",
        "  for i in range(1,5):\n",
        "    df_name = df[df[\"Cau14'\"]== i]\n",
        "    df_name = delete_noise_threshold(df_name)\n",
        "    df_n.append(df_name)\n",
        "  return df_n\n",
        "\n",
        "\n",
        "\n",
        "df_1 = df[[\"Cau11\",\"Cau12\" ,\"Cau14'\", \"Cau18\",'Cau21', 'Cau22', 'Cau23', 'Cau24', 'Cau27', 'Cau28', 'Cau29', 'Cau30']].copy()\n",
        "df_n = delete_noise(df_1)\n",
        "\n",
        "n = len(df_n[0]) + len(df_n[1])+ len(df_n[2])+ len(df_n[3])\n",
        "print(n)"
      ],
      "metadata": {
        "id": "vBDtuFu_JYq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_n[0]))\n",
        "print(len(df_n[1]))\n",
        "\n",
        "print( len(df_n[2]))\n",
        "print( len(df_n[3]))\n",
        "\n"
      ],
      "metadata": {
        "id": "u94v0fewMw95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Cau14'\"].value_counts()"
      ],
      "metadata": {
        "id": "6AarLQ8TQQms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def concat_and_shuffle(dataframes):\n",
        "    # Hợp toàn bộ dữ liệu từ danh sách DataFrame\n",
        "    concatenated_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "    # Xáo trộn dữ liệu\n",
        "    shuffled_df = shuffle(concatenated_df).reset_index(drop=True)\n",
        "\n",
        "    return shuffled_df\n",
        "\n",
        "# Example usage:\n",
        "# df_n là danh sách các DataFrame\n",
        "df_combined = concat_and_shuffle(df_n)\n"
      ],
      "metadata": {
        "id": "pDPawOuVP8JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_select = [\"Cau11\" ,\"Cau12\",\"Cau18\",'Cau21', 'Cau22', 'Cau23', 'Cau24', 'Cau27', 'Cau28', 'Cau29', 'Cau30']\n",
        "\n",
        "# ,\"Cau24*\", 'Cau26'\n",
        "X = df_combined[columns_to_select].copy()\n",
        "y = df_combined[\"Cau14'\"].copy() # Target\n",
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=10)"
      ],
      "metadata": {
        "id": "fAnvY1zwQKgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_combined.to_csv(\"data svm delete noise.csv\")"
      ],
      "metadata": {
        "id": "OIX7UgdQQ3Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "id": "8rlK-ObxQs3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts()"
      ],
      "metadata": {
        "id": "1ykMDJP8QtFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "param = {'C': 1, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
        "model =  svm.SVC( **param)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "# # Create a svm Classifier\n",
        "# for param in params:\n",
        "#     clf = svm.SVC(C=param[\"C\"], gamma=param[\"gamma\"], kernel=param[\"kernel\"], degree=param[\"degree\"])  # Linear Kernel\n",
        "\n",
        "#     # Train the model using the training sets\n",
        "#     clf.fit(X_train, y_train)\n",
        "\n",
        "#     # Predict the response for the test dataset\n",
        "#     y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"class 3\"],\n",
        "            yticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"class 3\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(f\"Confusion Matrix (C={param['C']}, gamma={param['gamma']}, kernel={param['kernel']}, degree={param['degree']})\")\n",
        "plt.show()\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "#     print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "o-fiqV71RYzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "perm_importance = permutation_importance(model, X_train, y_train)\n",
        "\n",
        "# Making the sum of feature importance being equal to 1.0,\n",
        "# so feature importance can be understood as percentage\n",
        "perm_importance_normalized = perm_importance.importances_mean/perm_importance.importances_mean.sum()\n",
        "\n",
        "# Feature's name (considering your X a DataFrame)\n",
        "feature_names = X.columns\n",
        "features = np.array(feature_names)\n",
        "\n",
        "# Sort to plot in order of importance\n",
        "sorted_idx = perm_importance_normalized.argsort()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(13,5))\n",
        "plt.title('Feature Importance',fontsize=20)\n",
        "plt.barh(features[sorted_idx], perm_importance_normalized[sorted_idx], color='b', align='center')\n",
        "plt.xlabel('Relative Importance', fontsize=15)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "for index, value in enumerate(perm_importance_normalized[sorted_idx]):\n",
        "    plt.text(value, index,\n",
        "             str(round(value,2)), fontsize=15)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "775uLCWjSNCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Giả sử bạn có một danh sách các DataFrame df_list, mỗi DataFrame tương ứng với một nhãn\n",
        "\n",
        "# Số lượng dữ liệu mới bạn muốn tạo\n",
        "num_new_samples = 1000\n",
        "\n",
        "# Mảng để lưu trữ dữ liệu mới\n",
        "new_data_list = []\n",
        "\n",
        "# Duyệt qua từng nhãn\n",
        "for df_label in df_n:\n",
        "    # Duyệt qua từng feature của mỗi nhãn\n",
        "    new_data = pd.DataFrame()\n",
        "    for feature in df_label.columns:\n",
        "        if feature != \"Cau14'\":\n",
        "          # Tính toán các tham số của phân phối (mean và standard deviation)\n",
        "          mean_feature = df_label[feature].mean()\n",
        "          std_dev_feature = df_label[feature].std()\n",
        "\n",
        "          # Tạo dữ liệu mới cho từng feature dựa trên phân phối xác suất của feature hiện có\n",
        "          new_samples_feature = np.random.normal(loc=mean_feature, scale=std_dev_feature, size=num_new_samples)\n",
        "\n",
        "          # Thêm feature mới vào DataFrame mới\n",
        "          new_data[feature] = new_samples_feature\n",
        "\n",
        "    # Thêm DataFrame mới vào danh sách\n",
        "    new_data_list.append(new_data)\n",
        "\n",
        "# new_data_list chứa các DataFrame mới, mỗi DataFrame có dữ liệu mới cho mỗi nhãn và feature tương ứng\n"
      ],
      "metadata": {
        "id": "qS9hWFvLdIa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_list[0]"
      ],
      "metadata": {
        "id": "0c1prNCIdtxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_list[0][\"Cau14'\"]=1\n",
        "new_data_list[1][\"Cau14'\"]=2\n",
        "new_data_list[2][\"Cau14'\"]=3\n",
        "new_data_list[3][\"Cau14'\"]=4"
      ],
      "metadata": {
        "id": "Q9Tt663xeSwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df= concat_and_shuffle(new_data_list)"
      ],
      "metadata": {
        "id": "9BlYdu6rjRzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.to_csv(\"data sampling gpt.csv\")"
      ],
      "metadata": {
        "id": "6fm8bUrhj3SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.concat([df_combined, new_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "Vxzd20RmkGBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_select = [\"Cau11\" ,\"Cau12\",\"Cau18\",'Cau21', 'Cau22', 'Cau23', 'Cau24', 'Cau27', 'Cau28', 'Cau29', 'Cau30']\n",
        "\n",
        "# ,\"Cau24*\", 'Cau26'\n",
        "X = combined_df[columns_to_select].copy()\n",
        "y = combined_df[\"Cau14'\"].copy() # Target\n",
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=10)\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "param = {'C': 1, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
        "model =  svm.SVC( **param)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "# # Create a svm Classifier\n",
        "# for param in params:\n",
        "#     clf = svm.SVC(C=param[\"C\"], gamma=param[\"gamma\"], kernel=param[\"kernel\"], degree=param[\"degree\"])  # Linear Kernel\n",
        "\n",
        "#     # Train the model using the training sets\n",
        "#     clf.fit(X_train, y_train)\n",
        "\n",
        "#     # Predict the response for the test dataset\n",
        "#     y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"class 3\"],\n",
        "            yticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"class 3\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(f\"Confusion Matrix (C={param['C']}, gamma={param['gamma']}, kernel={param['kernel']}, degree={param['degree']})\")\n",
        "plt.show()\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "#     print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "JkOOS4PNjZsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "perm_importance = permutation_importance(model, X_train, y_train)\n",
        "\n",
        "# Making the sum of feature importance being equal to 1.0,\n",
        "# so feature importance can be understood as percentage\n",
        "perm_importance_normalized = perm_importance.importances_mean/perm_importance.importances_mean.sum()\n",
        "\n",
        "# Feature's name (considering your X a DataFrame)\n",
        "feature_names = X.columns\n",
        "features = np.array(feature_names)\n",
        "\n",
        "# Sort to plot in order of importance\n",
        "sorted_idx = perm_importance_normalized.argsort()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(13,5))\n",
        "plt.title('Feature Importance',fontsize=20)\n",
        "plt.barh(features[sorted_idx], perm_importance_normalized[sorted_idx], color='b', align='center')\n",
        "plt.xlabel('Relative Importance', fontsize=15)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "for index, value in enumerate(perm_importance_normalized[sorted_idx]):\n",
        "    plt.text(value, index,\n",
        "             str(round(value,2)), fontsize=15)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "59DsTmWKK_rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gộp lại hai cột với nhau ví dụ  như feature 1 có nhãn là [1,2,3,4,5]\n",
        "feature 2 có nhãn là [1,2,3,4,5]"
      ],
      "metadata": {
        "id": "1I4336wlZpuT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oRxMZ1mOVguh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "categories = ['< 1H', '1H - 2H', '2H - 3H', '> 3H']\n",
        "\n",
        "# Lấy dữ liệu từ cột 'Cau12' và 'Cau14'\n",
        "selected_columns = ['Cau12', \"Cau14'\"]\n",
        "selected_data = df[selected_columns]\n",
        "\n",
        "# Ánh xạ giữa giá trị hiện tại và nhãn mới cho Cau12\n",
        "label_mapping = {\n",
        "    1: 'Rất ít',\n",
        "    2: 'Ít',\n",
        "    3: 'Trung bình',\n",
        "    4: 'Nhiều',\n",
        "    5: 'Rất nhiều'\n",
        "}\n",
        "\n",
        "# Tạo một danh sách thứ tự tương ứng\n",
        "order_list = ['Rất ít', 'Ít', 'Trung bình', 'Nhiều', 'Rất nhiều']\n",
        "\n",
        "# Áp dụng ánh xạ và đặt kiểu dữ liệu\n",
        "selected_data['Cau12'] = selected_data['Cau12'].replace(label_mapping)\n",
        "selected_data['Cau12'] = pd.Categorical(selected_data['Cau12'], categories=order_list, ordered=True)\n",
        "\n",
        "by_country = selected_data.groupby(['Cau12', \"Cau14'\"]).size().reset_index(name='n')\n",
        "\n",
        "total_by_country = by_country.groupby('Cau12')['n'].sum().reset_index(name='total')\n",
        "\n",
        "top_countries = total_by_country.nlargest(15, 'total')\n",
        "\n",
        "by_country_top = by_country[by_country['Cau12'].isin(top_countries['Cau12'])]\n",
        "\n",
        "# Thống kê dữ liệu\n",
        "data_counts = selected_data.melt(var_name='Question', value_name='Response').groupby(['Question', 'Response']).size().reset_index(name='Count')\n",
        "\n",
        "# Vẽ biểu đồ bằng seaborn và gán đối tượng Axes cho biến ax\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.barplot(x=\"Cau14'\", y='n', hue='Cau12', data=by_country_top, dodge=True)\n",
        "\n",
        "# Thay đổi tên của x-axis và labels của legend\n",
        "ax.set_xticklabels(categories)\n",
        "ax.legend(title='Sử dụng ngoài việc học & nghiên cứu', title_fontsize=12, loc='upper right')\n",
        "plt.xlabel('Thời gian sử dụng ChatGPT')\n",
        "plt.ylabel('Số lượng người dùng')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PskYaV1IsufP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "categories = ['< 1H', '1H - 2H', '2H - 3H', '> 3H']\n",
        "\n",
        "# Lấy dữ liệu từ cột 'Cau11' và 'Cau14'\n",
        "selected_columns = ['Cau11', \"Cau14'\"]\n",
        "selected_data = df[selected_columns]\n",
        "\n",
        "# Ánh xạ giữa giá trị hiện tại và nhãn mới cho Cau11\n",
        "label_mapping = {\n",
        "    1: 'Rất ít',\n",
        "    2: 'Ít',\n",
        "    3: 'Trung bình',\n",
        "    4: 'Nhiều',\n",
        "    5: 'Rất nhiều'\n",
        "}\n",
        "\n",
        "# Tạo một danh sách thứ tự tương ứng\n",
        "order_list = ['Rất ít', 'Ít', 'Trung bình', 'Nhiều', 'Rất nhiều']\n",
        "\n",
        "# Áp dụng ánh xạ và đặt kiểu dữ liệu\n",
        "selected_data['Cau11'] = selected_data['Cau11'].replace(label_mapping)\n",
        "selected_data['Cau11'] = pd.Categorical(selected_data['Cau11'], categories=order_list, ordered=True)\n",
        "\n",
        "by_country = selected_data.groupby(['Cau11', \"Cau14'\"]).size().reset_index(name='n')\n",
        "\n",
        "total_by_country = by_country.groupby('Cau11')['n'].sum().reset_index(name='total')\n",
        "\n",
        "top_countries = total_by_country.nlargest(15, 'total')\n",
        "\n",
        "by_country_top = by_country[by_country['Cau11'].isin(top_countries['Cau11'])]\n",
        "\n",
        "# Thống kê dữ liệu\n",
        "data_counts = selected_data.melt(var_name='Question', value_name='Response').groupby(['Question', 'Response']).size().reset_index(name='Count')\n",
        "\n",
        "# Vẽ biểu đồ bằng seaborn và gán đối tượng Axes cho biến ax\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.barplot(x=\"Cau14'\", y='n', hue='Cau11', data=by_country_top, dodge=True, palette=\"Set2\")\n",
        "\n",
        "# Thay đổi tên của x-axis và labels của legend\n",
        "ax.set_xticklabels(categories)\n",
        "ax.legend(title='Sử dụng trong việc học & nghiên cứu', title_fontsize=12, loc='upper right')\n",
        "plt.xlabel('Thời gian sử dụng ChatGPT')\n",
        "plt.ylabel('Số lượng người dùng')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0ifFEr3MtKx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4zYQk3ATTymP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id \"1etNhInSO3a6X2jgxHDAQ0UTcGk0KhsY4\""
      ],
      "metadata": {
        "id": "WMm8DUN-3n_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UznQmQOcteXF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "#Libraries for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Modelling\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Tree Visualisation\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image\n",
        "import graphviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChVBnfHSbtYz"
      },
      "source": [
        "**LOAD DỮ LIỆU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRKY6ciAX9KP"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(\"NCKH_dachuanhoa.xlsx\")\n",
        "df.loc[:,:].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kekyp9_Qx4c"
      },
      "outputs": [],
      "source": [
        "column_all_for_x = df.loc[:,\"Cau8\":'Cau36']\n",
        "columns_to_select_x = column_all_for_x.drop(['Cau13',\"Cau14'\",'Cau14','Cau15','Cau16'], axis=1)\n",
        "columns_to_select = ['Cau11','Cau12','Cau31','Cau25','Cau35','Cau20','Cau24','Cau36','Cau30','Cau23','Cau29']\n",
        "# ,\"Cau24*\", 'Cau26'\n",
        "X = df[columns_to_select].copy()\n",
        "y = df.loc[:,\"Cau14'\"].copy() # Target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns"
      ],
      "metadata": {
        "id": "nbnZOYEgcENW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41, stratify=y)"
      ],
      "metadata": {
        "id": "NLL5j9vMu3cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "\n",
        "# Định ra các giá trị tham số để thử nghiệm\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'max_iter': [10000],\n",
        "    'C': [0.1, 0.5, 1, 10, 100]\n",
        "}\n",
        "\n",
        "# Tìm kiếm các tham số tối ưu\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Sử dụng tham số tối ưu để đào tạo mô hình\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Dự đoán và đánh giá mô hình trên tập kiểm tra\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Calculate the confusion matrix for the best model\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"class 3\"],\n",
        "            yticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"class 3\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "# plt.title(f\"Confusion Matrix (C={param['C']}, gamma={param['gamma']}, kernel={param['kernel']}, degree={param['degree']})\")\n",
        "plt.show()\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "YhMbcxVEd9r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sử dụng RFE để đánh giá tầm quan trọng của các đặc trưng\n",
        "rfe = RFE(estimator=best_model)\n",
        "model_fit = rfe.fit(X_train, y_train)\n",
        "\n",
        "# Lấy chỉ số của các đặc trưng được chọn\n",
        "selected_features = pd.Series(data=model_fit.ranking_, index=X_train.columns)\n",
        "\n",
        "# Chọn chỉ các đặc trưng có rank bằng 1\n",
        "signi_feat_rfe = selected_features[selected_features == 1].index\n",
        "\n",
        "# Sắp xếp chỉ số của các đặc trưng được chọn theo rank\n",
        "sorted_features = selected_features.sort_values(ascending=False)\n",
        "\n",
        "# Vẽ biểu đồ tầm quan trọng của các đặc trưng sau khi sử dụng RFE (đã sắp xếp)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sorted_features.plot(kind='bar')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Ranking')\n",
        "plt.title('Feature Importance Ranking (RFE) - Sorted')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DlnJ7uVli7Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "perm_importance = permutation_importance(best_model, X_train, y_train)\n",
        "\n",
        "# Making the sum of feature importance being equal to 1.0,\n",
        "# so feature importance can be understood as percentage\n",
        "perm_importance_normalized = perm_importance.importances_mean/perm_importance.importances_mean.sum()\n",
        "\n",
        "# Feature's name (considering your X a DataFrame)\n",
        "feature_names = X.columns\n",
        "features = np.array(feature_names)\n",
        "\n",
        "# Sort to plot in order of importance\n",
        "sorted_idx = perm_importance_normalized.argsort()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(13,5))\n",
        "plt.title('Feature Importance',fontsize=20)\n",
        "plt.barh(features[sorted_idx], perm_importance_normalized[sorted_idx], color='b', align='center')\n",
        "plt.xlabel('Relative Importance', fontsize=15)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "for index, value in enumerate(perm_importance_normalized[sorted_idx]):\n",
        "    plt.text(value, index,\n",
        "             str(round(value,2)), fontsize=15)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "'Cau11','Cau12','Cau31','Cau25','Cau35','Cau20','Cau24','Cau36','Cau30','Cau19','Cau23','Cau28','Cau29'"
      ],
      "metadata": {
        "id": "mK8DPCOdhee2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_column_charts(df, column_name):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "    # Biểu đồ tròn\n",
        "    df[column_name].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, ax=axes[0])\n",
        "    axes[0].set_title(f'Pie Chart for {column_name}')\n",
        "\n",
        "    # Biểu đồ cột\n",
        "    sns.countplot(x=column_name, data=df, palette='viridis', ax=axes[1])\n",
        "    axes[1].set_title(f'Column Chart for {column_name}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ví dụ sử dụng:\n",
        "# # Thay 'TenCot' bằng tên cột bạn muốn vẽ\n",
        "# plot_column_charts(df, 'TenCot')\n",
        "def view_data(df, name):\n",
        "  for i in range(1,5):\n",
        "    df_12 = df[df[\"Cau14'\"]==i]\n",
        "    plot_column_charts(df_12, name)\n"
      ],
      "metadata": {
        "id": "TbrkHP9qEDub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def delete_noise_threshold( df_name):\n",
        "  for column in df_name.columns:\n",
        "    if column != \"Cau14'\":\n",
        "      value_counts = df_name[column].value_counts(normalize=True)\n",
        "      # Xác định và loại bỏ giá trị nhiễu dựa trên phân phối xác suất của feature\n",
        "      threshold = 0.05\n",
        "      noise_values = value_counts[value_counts < threshold].index\n",
        "      df_name = df_name[~df_name[column].isin(noise_values)]\n",
        "  return df_name\n",
        "\n",
        "\n",
        "\n",
        "def delete_noise(df):\n",
        "  df_n = []\n",
        "  for i in range(1,5):\n",
        "    df_name = df[df[\"Cau14'\"] == i]\n",
        "    df_name = delete_noise_threshold(df_name)\n",
        "    df_n.append(df_name)\n",
        "  return df_n\n",
        "\n",
        "\n",
        "\n",
        "df_1 = df[['Cau11','Cau12',\"Cau14'\",'Cau31','Cau25','Cau35','Cau20','Cau24','Cau36','Cau30','Cau19','Cau23','Cau28','Cau29']].copy()\n",
        "df_n = delete_noise(df_1)\n",
        "\n",
        "n = len(df_n[0]) + len(df_n[1])+ len(df_n[2])+ len(df_n[3])\n",
        "print(n)"
      ],
      "metadata": {
        "id": "p4YLs03xEN_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_n[0]))\n",
        "print(len(df_n[1]))\n",
        "print( len(df_n[2]))\n",
        "print( len(df_n[3]))"
      ],
      "metadata": {
        "id": "hh9zPNTRETUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def concat_and_shuffle(dataframes):\n",
        "    # Hợp toàn bộ dữ liệu từ danh sách DataFrame\n",
        "    concatenated_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "    # Xáo trộn dữ liệu\n",
        "    shuffled_df = shuffle(concatenated_df).reset_index(drop=True)\n",
        "\n",
        "    return shuffled_df\n",
        "\n",
        "# Example usage:\n",
        "# df_n là danh sách các DataFrame\n",
        "df_combined = concat_and_shuffle(df_n)\n"
      ],
      "metadata": {
        "id": "7AcTRyTfEeVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_select = ['Cau11','Cau12','Cau31','Cau25','Cau35','Cau20','Cau24','Cau36','Cau30','Cau19','Cau23','Cau28','Cau29']\n",
        "\n",
        "# ,\"Cau24*\", 'Cau26'\n",
        "X = df_combined[columns_to_select].copy()\n",
        "y = df_combined[\"Cau14'\"].copy() # Target\n",
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=41)"
      ],
      "metadata": {
        "id": "JSjbjMQ_Eqq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "id": "FdKOu5J6E412"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts()"
      ],
      "metadata": {
        "id": "wPNThgZ5GDIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "\n",
        "# Định ra các giá trị tham số để thử nghiệm\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'max_iter': [10000],\n",
        "    'C': [0.1, 0.5, 1, 10, 100]\n",
        "}\n",
        "\n",
        "# Tìm kiếm các tham số tối ưu\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Sử dụng tham số tối ưu để đào tạo mô hình\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Dự đoán và đánh giá mô hình trên tập kiểm tra\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Calculate the confusion matrix for the best model\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"class 3\"],\n",
        "            yticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"class 3\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "# plt.title(f\"Confusion Matrix (C={param['C']}, gamma={param['gamma']}, kernel={param['kernel']}, degree={param['degree']})\")\n",
        "plt.show()\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "1Hdmv7r0GFE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "perm_importance = permutation_importance(best_model, X_train, y_train)\n",
        "\n",
        "# Making the sum of feature importance being equal to 1.0,\n",
        "# so feature importance can be understood as percentage\n",
        "perm_importance_normalized = perm_importance.importances_mean/perm_importance.importances_mean.sum()\n",
        "\n",
        "# Feature's name (considering your X a DataFrame)\n",
        "feature_names = X.columns\n",
        "features = np.array(feature_names)\n",
        "\n",
        "# Sort to plot in order of importance\n",
        "sorted_idx = perm_importance_normalized.argsort()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(13,5))\n",
        "plt.title('Feature Importance',fontsize=20)\n",
        "plt.barh(features[sorted_idx], perm_importance_normalized[sorted_idx], color='b', align='center')\n",
        "plt.xlabel('Relative Importance', fontsize=15)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "for index, value in enumerate(perm_importance_normalized[sorted_idx]):\n",
        "    plt.text(value, index,\n",
        "             str(round(value,2)), fontsize=15)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jcUzZnHkGfkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Giả sử bạn có một danh sách các DataFrame df_list, mỗi DataFrame tương ứng với một nhãn\n",
        "\n",
        "# Số lượng dữ liệu mới bạn muốn tạo\n",
        "num_new_samples = 1000\n",
        "\n",
        "# Mảng để lưu trữ dữ liệu mới\n",
        "new_data_list = []\n",
        "\n",
        "# Duyệt qua từng nhãn\n",
        "for df_label in df_n:\n",
        "    # Duyệt qua từng feature của mỗi nhãn\n",
        "    new_data = pd.DataFrame()\n",
        "    for feature in df_label.columns:\n",
        "        if feature != \"Cau14'\":\n",
        "          # Tính toán các tham số của phân phối (mean và standard deviation)\n",
        "          mean_feature = df_label[feature].mean()\n",
        "          std_dev_feature = df_label[feature].std()\n",
        "\n",
        "          # Tạo dữ liệu mới cho từng feature dựa trên phân phối xác suất của feature hiện có\n",
        "          new_samples_feature = np.random.normal(loc=mean_feature, scale=std_dev_feature, size=num_new_samples)\n",
        "\n",
        "          # Thêm feature mới vào DataFrame mới\n",
        "          new_data[feature] = new_samples_feature\n",
        "\n",
        "    # Thêm DataFrame mới vào danh sách\n",
        "    new_data_list.append(new_data)\n",
        "\n",
        "# new_data_list chứa các DataFrame mới, mỗi DataFrame có dữ liệu mới cho mỗi nhãn và feature tương ứng\n"
      ],
      "metadata": {
        "id": "MFYmfz3bG-ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_list[0]"
      ],
      "metadata": {
        "id": "DsvmpQLYHAPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_list[0][\"Cau14'\"]=1\n",
        "new_data_list[1][\"Cau14'\"]=2\n",
        "new_data_list[2][\"Cau14'\"]=3\n",
        "new_data_list[3][\"Cau14'\"]=4"
      ],
      "metadata": {
        "id": "1kvYB2lbHC1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df= concat_and_shuffle(new_data_list)"
      ],
      "metadata": {
        "id": "XjRSeg0KHEys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.to_csv(\"data sampling gpt.csv\")"
      ],
      "metadata": {
        "id": "UO70tPcUI7ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.concat([df_combined, new_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "0c77j7u7I9mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_select = ['Cau11','Cau12','Cau31','Cau25','Cau35','Cau20','Cau24','Cau36','Cau30','Cau19','Cau23','Cau28','Cau29']\n",
        "\n",
        "# ,\"Cau24*\", 'Cau26'\n",
        "X = combined_df[columns_to_select].copy()\n",
        "y = combined_df[\"Cau14'\"].copy() # Target\n",
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=41,stratify=y)\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "\n",
        "# Định ra các giá trị tham số để thử nghiệm\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'max_iter': [10000],\n",
        "    'C': [0.1, 0.5, 1, 10, 100]\n",
        "}\n",
        "\n",
        "# Tìm kiếm các tham số tối ưu\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Sử dụng tham số tối ưu để đào tạo mô hình\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Dự đoán và đánh giá mô hình trên tập kiểm tra\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Calculate the confusion matrix for the best model\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"class 3\"],\n",
        "            yticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"class 3\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "# plt.title(f\"Confusion Matrix (C={param['C']}, gamma={param['gamma']}, kernel={param['kernel']}, degree={param['degree']})\")\n",
        "plt.show()\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "uXcv8ZXSJB8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LƯU MODEL"
      ],
      "metadata": {
        "id": "DxK94vxlRRTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lưu model\n",
        "# import pickle\n",
        "# filename = 'logistic_regression.pkl'\n",
        "\n",
        "# # Lưu mô hình vào tệp pkl\n",
        "# with open('logistic_regression.pkl', 'wb') as file:\n",
        "#     pickle.dump(best_model, file)\n",
        "\n",
        "# # Đọc model\n",
        "# import pickle\n",
        "\n",
        "# # Đọc mô hình từ tệp pkl\n",
        "# with open('logistic_regression.pkl', 'rb') as file:\n",
        "#     loaded_model = pickle.load(file)"
      ],
      "metadata": {
        "id": "YKkFhtvmRFTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Xây dựng mô hình\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Lấy đặc trưng quan trọng từ mô hình\n",
        "feature_importances = clf.feature_importances_\n",
        "\n",
        "# Hiển thị đặc trưng quan trọng theo thứ tự giảm dần\n",
        "indices = np.argsort(feature_importances)[::-1]\n",
        "for f in range(X_train.shape[1]):\n",
        "    print(f\"{X_train.columns[indices[f]]}: {feature_importances[indices[f]]}\")\n",
        "\n",
        "# Vẽ biểu đồ đặc trưng quan trọng\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(X_train.shape[1]), feature_importances[indices], align=\"center\")\n",
        "plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xcktAAYbRTdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tính feature importance\n",
        "feature_importance = clf.feature_importances_\n",
        "\n",
        "# Tạo một DataFrame để hiển thị thông tin\n",
        "import pandas as pd\n",
        "feature_importance_df = pd.DataFrame({'Variable': X_train.columns, 'Importance': feature_importance})\n",
        "\n",
        "# Sắp xếp theo độ quan trọng giảm dần\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Hiển thị biểu đồ cột về độ quan trọng của các biến\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Variable', data=feature_importance_df, palette='viridis')\n",
        "\n",
        "# Thêm tiêu đề và định dạng\n",
        "plt.title('Feature Importance', fontsize=16)\n",
        "plt.xlabel('Importance', fontsize=14)\n",
        "plt.ylabel('Variable', fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "# Hiển thị giá trị của độ quan trọng trên từng cột\n",
        "for index, value in enumerate(feature_importance_df['Importance']):\n",
        "    plt.text(value, index, f'{value:.4f}', ha='left', va='center', fontsize=10, color='black')\n",
        "\n",
        "# Hiển thị lưới để dễ đọc\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "\n",
        "# Tăng khoảng cách giữa các cột để dễ nhìn\n",
        "plt.tight_layout()\n",
        "\n",
        "# Hiển thị biểu đồ\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ydFUtIDUKV6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_dict_ordered = {}\n",
        "def total_important(rf, svm, log, label):\n",
        "  total = rf / 15 + svm / 11 + log / 13\n",
        "  list_dict_ordered[label] = total\n",
        "total_important(0.05, 0.02, 0.04, '29')\n",
        "print(list_dict_ordered)"
      ],
      "metadata": {
        "id": "tyjyaVwEXwxp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}